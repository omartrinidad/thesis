\documentclass{article}

% https://tex.stackexchange.com/questions/106988/package-for-drawing-rdf-graphs

\title{
Distributed AMIE+\\
\large Preliminary Notes\\
of the Thesis Project\\
}
\author{Omar Trinidad Guti\'errez M\'endez}

\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\begin{document}
\maketitle

\section{Introduction}

Knowledge bases (KB) have the purpose of representing and store knowledge in a
machine-readable format. Some well-known KBs are DBpedia~\cite{dbpedia-swj},
NELL, YAGO~\cite{suchanek2007yago}, or Freebase~\cite{bollacker2008freebase}. A
usual task executed in these databases is mining logical rules, that is, find
unknown relationships between entities. For example,

\begin{equation*}
livesIn(a, x) and marriedTo(a, b) => livesIn(b, x)
\end{equation*}

However,  these databases are designed under the idea of Open World Assumption
(OWA), that means, if the database does not contain a fact, we are not assuming
that this fact is false, as happens under the Closed World Assumption (CWA).

Finding these relations in huge datasets, and under the OWA setting is a
challenging task. This problem was addressed by Galárraga et
al.~\cite{galarraga2013amie}  who proposed Association Rule Mining under
Incomplete Evidence (AMIE) and later suggested an improved version of the same
method that they simple named AMIE+~\cite{galarraga2015fast}.

The purpose of the current project is to explore AMIE+ and implement it in a
distributed context.

\subsection{Theory}

Knowledge Bases $KB$ are collections of facts; every fact is represented by a
relation between a subject and object $r(s, o)$.

In this work, we are focused on KBs modeled using the W3C standard Resource
Description Framework~\cite{rdf} (RDF).

In RDF, the facts are represented as triples $s, r, o$.

Horn rules

An \textit{atom} is a fact with different variables at the subject and object.
A Horn rule is composed of a head and a body. The head is a single atom and the
body is a set of atoms.

% ¿Es relevante?
% The facts in KBs are divided in A-Box and T-Box.

\subsection{Similar works}

The task of finding new logical rules given a KB has been addressed from
multiple angles. For example, ILP based approaches, relational machine learning
or hybrid approaches.

One advantage, from AMIE over relational machine learning approaches, is that
AMIE has better interpretability, which is a crucial in the Data Science world.
So, with AMIE, it is possible to mine logical rules where there is a
correlation in the data.

\subsection{AMIE}

% The purpose of AMIE is to generate Horn rules.

Inside AMIE, the Partial Completeness Assumption (PCA) was used to guess the
so-called counterexamples for rules.

In the PCA we say that a subject-relation pair is complete if it does exists
an object that for that s,r.

Assume that if the KB knows relations for some subject then knows all the set
of values.

%\subsubsection{Completeness}
%Lets say that $KB*$ contains every fact of the world.

\subsubsection{Rules and language bias}

\textbf{ToDo}: What a rule is, draw some diagrams\ldots

In order to limit the size of the search space, AMIE uses constraints that are called
\textit{language bias}

% ToDo
% Tikz figure showing examples of rules.
% Tikz figures for SANSA stack.

In order to limit the size of the search space, AMIE uses some constraints on
the structure of the desired rules.

Connectivity: Two atoms in a rule are connected if they share a variable or
entity. A rule is connected when every atom is connected transitively to the
rest of atoms. 

\subsection{AMIE plus}

In AMIE+ it was aggregated pruning strategies and approximations that allowed
to explore the search space more efficiently.

\subsection{SANSA Stack}

SANSA is a platform whose purpose is\ldots

\bibliographystyle{plain}
\bibliography{notes}

\end{document}
